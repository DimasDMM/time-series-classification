{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Dropout-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Import functions from relative path\n",
    "from lib.ModelLoader import ModelLoader\n",
    "from lib.ModelEvaluator import ModelEvaluator\n",
    "from lib.AttentionLayer import AttentionLayer as Attention\n",
    "from lib.HyperparameterOptimizer import HyperparameterOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_path = os.path.abspath(os.path.join('../artifacts'))\n",
    "model_loader = ModelLoader(artifacts_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2520\n",
      "Test: 1081\n",
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "DATASET = '../data/ford/FordA.txt'\n",
    "\n",
    "series = []\n",
    "labels = []\n",
    "\n",
    "with open(DATASET, 'r') as fp:\n",
    "    for line in fp:\n",
    "        values = line.strip().split()\n",
    "        labels.append(float(values[0]) == 1)\n",
    "        series.append(np.array(values[1:], dtype=np.float32))\n",
    "\n",
    "# Transform into numpy arrays\n",
    "series = np.array(series)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# It is necessary to transform the array into 3D\n",
    "series = series.reshape(series.shape[0], series.shape[1], 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(series, labels, test_size=0.3)\n",
    "\n",
    "print('Train: %d' % len(X_train))\n",
    "print('Test: %d' % len(X_test))\n",
    "print('Data loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_length, metrics, model_params):\n",
    "    model = Sequential([\n",
    "        LSTM(100,\n",
    "             input_shape=(input_length, 1),\n",
    "             activation=model_params['lstm_activation'],\n",
    "             dropout=model_params['lstm_dropout'],\n",
    "             recurrent_dropout=model_params['recurrent_dropout'],\n",
    "             return_sequences=True),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.2, 'recurrent_dropout': 0.2}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 95s 1s/step - loss: 0.6490 - accuracy: 0.6329 - precision: 0.6272 - recall: 0.6337 - auc: 0.6879 - f1_score: 0.6614 - val_loss: 0.5754 - val_accuracy: 0.6929 - val_precision: 0.6545 - val_recall: 0.7392 - val_auc: 0.7693 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 98s 1s/step - loss: 0.5423 - accuracy: 0.7222 - precision: 0.7141 - recall: 0.7301 - auc: 0.8002 - f1_score: 0.6614 - val_loss: 0.5705 - val_accuracy: 0.6883 - val_precision: 0.6821 - val_recall: 0.6353 - val_auc: 0.7717 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 95s 1s/step - loss: 0.4915 - accuracy: 0.7718 - precision: 0.7650 - recall: 0.7767 - auc: 0.8448 - f1_score: 0.6614 - val_loss: 0.5842 - val_accuracy: 0.7151 - val_precision: 0.6706 - val_recall: 0.7784 - val_auc: 0.7925 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.4226 - accuracy: 0.8139 - precision: 0.8070 - recall: 0.8193 - auc: 0.8877 - f1_score: 0.6614 - val_loss: 0.5975 - val_accuracy: 0.7114 - val_precision: 0.6934 - val_recall: 0.6961 - val_auc: 0.7918 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 91s 1s/step - loss: 0.3620 - accuracy: 0.8460 - precision: 0.8382 - recall: 0.8530 - auc: 0.9203 - f1_score: 0.6614 - val_loss: 0.5711 - val_accuracy: 0.7280 - val_precision: 0.7338 - val_recall: 0.6647 - val_auc: 0.8060 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 91s 1s/step - loss: 0.3094 - accuracy: 0.8778 - precision: 0.8769 - recall: 0.8755 - auc: 0.9424 - f1_score: 0.6614 - val_loss: 0.5794 - val_accuracy: 0.7484 - val_precision: 0.7003 - val_recall: 0.8157 - val_auc: 0.8267 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.2486 - accuracy: 0.9004 - precision: 0.8976 - recall: 0.9012 - auc: 0.9624 - f1_score: 0.6614 - val_loss: 0.7113 - val_accuracy: 0.7317 - val_precision: 0.6698 - val_recall: 0.8510 - val_auc: 0.8262 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.2183 - accuracy: 0.9127 - precision: 0.9058 - recall: 0.9189 - auc: 0.9712 - f1_score: 0.6614 - val_loss: 0.6176 - val_accuracy: 0.7530 - val_precision: 0.7150 - val_recall: 0.7922 - val_auc: 0.8378 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.2, 'recurrent_dropout': 0.3}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.6481 - accuracy: 0.6737 - precision: 0.6556 - recall: 0.6963 - auc: 0.7391 - f1_score: 0.6553 - val_loss: 0.5793 - val_accuracy: 0.6910 - val_precision: 0.6618 - val_recall: 0.7059 - val_auc: 0.7629 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 1455s 18s/step - loss: 0.5463 - accuracy: 0.7187 - precision: 0.7158 - recall: 0.7141 - auc: 0.7956 - f1_score: 0.6614 - val_loss: 0.6302 - val_accuracy: 0.6735 - val_precision: 0.6129 - val_recall: 0.8353 - val_auc: 0.7761 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 101s 1s/step - loss: 0.4841 - accuracy: 0.7623 - precision: 0.7520 - recall: 0.7743 - auc: 0.8471 - f1_score: 0.6614 - val_loss: 0.5620 - val_accuracy: 0.7058 - val_precision: 0.7222 - val_recall: 0.6118 - val_auc: 0.8018 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.4177 - accuracy: 0.8123 - precision: 0.8044 - recall: 0.8193 - auc: 0.8923 - f1_score: 0.6614 - val_loss: 0.5856 - val_accuracy: 0.7123 - val_precision: 0.6963 - val_recall: 0.6922 - val_auc: 0.7980 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.3654 - accuracy: 0.8393 - precision: 0.8426 - recall: 0.8297 - auc: 0.9178 - f1_score: 0.6614 - val_loss: 0.5628 - val_accuracy: 0.7336 - val_precision: 0.6785 - val_recall: 0.8275 - val_auc: 0.8268 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.3019 - accuracy: 0.8782 - precision: 0.8764 - recall: 0.8771 - auc: 0.9452 - f1_score: 0.6614 - val_loss: 0.5604 - val_accuracy: 0.7438 - val_precision: 0.7145 - val_recall: 0.7608 - val_auc: 0.8302 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.2498 - accuracy: 0.8968 - precision: 0.8956 - recall: 0.8956 - auc: 0.9622 - f1_score: 0.6614 - val_loss: 0.5895 - val_accuracy: 0.7382 - val_precision: 0.7389 - val_recall: 0.6882 - val_auc: 0.8307 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.1959 - accuracy: 0.9258 - precision: 0.9273 - recall: 0.9221 - auc: 0.9764 - f1_score: 0.6614 - val_loss: 0.7325 - val_accuracy: 0.7373 - val_precision: 0.7062 - val_recall: 0.7588 - val_auc: 0.8149 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.2, 'recurrent_dropout': 0.5}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.6685 - accuracy: 0.6590 - precision: 0.6436 - recall: 0.6729 - auc: 0.7178 - f1_score: 0.6553 - val_loss: 0.5905 - val_accuracy: 0.6920 - val_precision: 0.6879 - val_recall: 0.6353 - val_auc: 0.7567 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.5711 - accuracy: 0.7036 - precision: 0.6948 - recall: 0.7133 - auc: 0.7758 - f1_score: 0.6614 - val_loss: 0.5686 - val_accuracy: 0.7058 - val_precision: 0.6791 - val_recall: 0.7137 - val_auc: 0.7722 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.5032 - accuracy: 0.7591 - precision: 0.7544 - recall: 0.7598 - auc: 0.8357 - f1_score: 0.6614 - val_loss: 0.5639 - val_accuracy: 0.6975 - val_precision: 0.6488 - val_recall: 0.7824 - val_auc: 0.7981 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 1072s 14s/step - loss: 0.4504 - accuracy: 0.7960 - precision: 0.7950 - recall: 0.7912 - auc: 0.8721 - f1_score: 0.6614 - val_loss: 0.5206 - val_accuracy: 0.7327 - val_precision: 0.7028 - val_recall: 0.7510 - val_auc: 0.8192 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 4528s 57s/step - loss: 0.3851 - accuracy: 0.8337 - precision: 0.8257 - recall: 0.8410 - auc: 0.9096 - f1_score: 0.6614 - val_loss: 0.5328 - val_accuracy: 0.7271 - val_precision: 0.7235 - val_recall: 0.6824 - val_auc: 0.8106 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 8136s 103s/step - loss: 0.3273 - accuracy: 0.8706 - precision: 0.8715 - recall: 0.8659 - auc: 0.9360 - f1_score: 0.6614 - val_loss: 0.6152 - val_accuracy: 0.7373 - val_precision: 0.7665 - val_recall: 0.6373 - val_auc: 0.8182 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 1699s 22s/step - loss: 0.2632 - accuracy: 0.8921 - precision: 0.8889 - recall: 0.8932 - auc: 0.9577 - f1_score: 0.6614 - val_loss: 0.6831 - val_accuracy: 0.7280 - val_precision: 0.7358 - val_recall: 0.6608 - val_auc: 0.8071 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 118s 1s/step - loss: 0.2257 - accuracy: 0.9139 - precision: 0.9112 - recall: 0.9149 - auc: 0.9685 - f1_score: 0.6614 - val_loss: 0.5988 - val_accuracy: 0.7604 - val_precision: 0.7337 - val_recall: 0.7725 - val_auc: 0.8391 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.2, 'recurrent_dropout': 0.7}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 93s 1s/step - loss: 0.6635 - accuracy: 0.6626 - precision: 0.6554 - recall: 0.6490 - auc: 0.7267 - f1_score: 0.6553 - val_loss: 0.5949 - val_accuracy: 0.6744 - val_precision: 0.6406 - val_recall: 0.7059 - val_auc: 0.7469 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 91s 1s/step - loss: 0.5660 - accuracy: 0.7052 - precision: 0.6961 - recall: 0.7157 - auc: 0.7816 - f1_score: 0.6614 - val_loss: 0.5933 - val_accuracy: 0.6716 - val_precision: 0.6765 - val_recall: 0.5824 - val_auc: 0.7467 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.5102 - accuracy: 0.7532 - precision: 0.7522 - recall: 0.7462 - auc: 0.8297 - f1_score: 0.6614 - val_loss: 0.5745 - val_accuracy: 0.6920 - val_precision: 0.6343 - val_recall: 0.8196 - val_auc: 0.7847 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 94s 1s/step - loss: 0.4579 - accuracy: 0.7865 - precision: 0.7830 - recall: 0.7855 - auc: 0.8672 - f1_score: 0.6614 - val_loss: 0.5658 - val_accuracy: 0.7160 - val_precision: 0.6683 - val_recall: 0.7902 - val_auc: 0.7996 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.4021 - accuracy: 0.8230 - precision: 0.8193 - recall: 0.8233 - auc: 0.9020 - f1_score: 0.6614 - val_loss: 0.5416 - val_accuracy: 0.7327 - val_precision: 0.7171 - val_recall: 0.7157 - val_auc: 0.8129 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 91s 1s/step - loss: 0.3441 - accuracy: 0.8639 - precision: 0.8512 - recall: 0.8779 - auc: 0.9289 - f1_score: 0.6614 - val_loss: 0.5935 - val_accuracy: 0.7401 - val_precision: 0.7313 - val_recall: 0.7098 - val_auc: 0.8189 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 92s 1s/step - loss: 0.3004 - accuracy: 0.8810 - precision: 0.8783 - recall: 0.8811 - auc: 0.9448 - f1_score: 0.6614 - val_loss: 0.5967 - val_accuracy: 0.7299 - val_precision: 0.7243 - val_recall: 0.6902 - val_auc: 0.8077 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 2447s 31s/step - loss: 0.2424 - accuracy: 0.9087 - precision: 0.9031 - recall: 0.9133 - auc: 0.9647 - f1_score: 0.6614 - val_loss: 0.6610 - val_accuracy: 0.7410 - val_precision: 0.7246 - val_recall: 0.7275 - val_auc: 0.8103 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.3, 'recurrent_dropout': 0.2}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 103s 1s/step - loss: 0.6868 - accuracy: 0.6473 - precision: 0.6349 - recall: 0.6501 - auc: 0.7071 - f1_score: 0.6553 - val_loss: 0.6047 - val_accuracy: 0.6762 - val_precision: 0.7162 - val_recall: 0.5196 - val_auc: 0.7450 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 83s 1s/step - loss: 0.5713 - accuracy: 0.7008 - precision: 0.6908 - recall: 0.7141 - auc: 0.7736 - f1_score: 0.6614 - val_loss: 0.5662 - val_accuracy: 0.7012 - val_precision: 0.6823 - val_recall: 0.6863 - val_auc: 0.7741 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 83s 1s/step - loss: 0.5137 - accuracy: 0.7496 - precision: 0.7440 - recall: 0.7518 - auc: 0.8268 - f1_score: 0.6614 - val_loss: 0.5495 - val_accuracy: 0.7243 - val_precision: 0.7227 - val_recall: 0.6745 - val_auc: 0.7917 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.4703 - accuracy: 0.7845 - precision: 0.7804 - recall: 0.7847 - auc: 0.8606 - f1_score: 0.6614 - val_loss: 0.5853 - val_accuracy: 0.7040 - val_precision: 0.6627 - val_recall: 0.7588 - val_auc: 0.7878 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.4153 - accuracy: 0.8183 - precision: 0.8111 - recall: 0.8241 - auc: 0.8928 - f1_score: 0.6614 - val_loss: 0.5427 - val_accuracy: 0.7345 - val_precision: 0.7226 - val_recall: 0.7098 - val_auc: 0.8090 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.3630 - accuracy: 0.8353 - precision: 0.8391 - recall: 0.8249 - auc: 0.9187 - f1_score: 0.6614 - val_loss: 0.6029 - val_accuracy: 0.7142 - val_precision: 0.6754 - val_recall: 0.7588 - val_auc: 0.8012 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.3135 - accuracy: 0.8798 - precision: 0.8774 - recall: 0.8795 - auc: 0.9404 - f1_score: 0.6614 - val_loss: 0.6327 - val_accuracy: 0.7086 - val_precision: 0.6449 - val_recall: 0.8510 - val_auc: 0.8224 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 1611s 20s/step - loss: 0.2600 - accuracy: 0.8952 - precision: 0.8946 - recall: 0.8932 - auc: 0.9587 - f1_score: 0.6614 - val_loss: 0.5963 - val_accuracy: 0.7447 - val_precision: 0.7017 - val_recall: 0.7980 - val_auc: 0.8289 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.3, 'recurrent_dropout': 0.3}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 1231s 16s/step - loss: 0.6658 - accuracy: 0.6529 - precision: 0.6369 - recall: 0.6695 - auc: 0.7208 - f1_score: 0.6553 - val_loss: 0.5960 - val_accuracy: 0.6688 - val_precision: 0.6203 - val_recall: 0.7686 - val_auc: 0.7599 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 92s 1s/step - loss: 0.5595 - accuracy: 0.7028 - precision: 0.6956 - recall: 0.7084 - auc: 0.7830 - f1_score: 0.6614 - val_loss: 0.5740 - val_accuracy: 0.7012 - val_precision: 0.6604 - val_recall: 0.7549 - val_auc: 0.7814 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 105s 1s/step - loss: 0.5085 - accuracy: 0.7508 - precision: 0.7478 - recall: 0.7478 - auc: 0.8311 - f1_score: 0.6614 - val_loss: 0.5542 - val_accuracy: 0.7151 - val_precision: 0.6843 - val_recall: 0.7353 - val_auc: 0.7996 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 120s 2s/step - loss: 0.4472 - accuracy: 0.7988 - precision: 0.7910 - recall: 0.8056 - auc: 0.8729 - f1_score: 0.6614 - val_loss: 0.5167 - val_accuracy: 0.7234 - val_precision: 0.7010 - val_recall: 0.7216 - val_auc: 0.8192 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.3829 - accuracy: 0.8444 - precision: 0.8377 - recall: 0.8498 - auc: 0.9114 - f1_score: 0.6614 - val_loss: 0.5376 - val_accuracy: 0.7456 - val_precision: 0.7484 - val_recall: 0.6941 - val_auc: 0.8256 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.3432 - accuracy: 0.8575 - precision: 0.8527 - recall: 0.8602 - auc: 0.9285 - f1_score: 0.6614 - val_loss: 0.5084 - val_accuracy: 0.7456 - val_precision: 0.7393 - val_recall: 0.7118 - val_auc: 0.8372 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 92s 1s/step - loss: 0.2836 - accuracy: 0.8833 - precision: 0.8795 - recall: 0.8851 - auc: 0.9513 - f1_score: 0.6614 - val_loss: 0.5591 - val_accuracy: 0.7632 - val_precision: 0.7510 - val_recall: 0.7451 - val_auc: 0.8369 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 91s 1s/step - loss: 0.2254 - accuracy: 0.9095 - precision: 0.9065 - recall: 0.9108 - auc: 0.9691 - f1_score: 0.6614 - val_loss: 0.6002 - val_accuracy: 0.7604 - val_precision: 0.7400 - val_recall: 0.7588 - val_auc: 0.8487 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.3, 'recurrent_dropout': 0.5}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 93s 1s/step - loss: 0.6741 - accuracy: 0.6395 - precision: 0.6282 - recall: 0.6382 - auc: 0.7075 - f1_score: 0.6553 - val_loss: 0.6086 - val_accuracy: 0.6411 - val_precision: 0.5971 - val_recall: 0.7353 - val_auc: 0.7354 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 93s 1s/step - loss: 0.5819 - accuracy: 0.6853 - precision: 0.6628 - recall: 0.7390 - auc: 0.7607 - f1_score: 0.6614 - val_loss: 0.5730 - val_accuracy: 0.6947 - val_precision: 0.6807 - val_recall: 0.6647 - val_auc: 0.7685 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 94s 1s/step - loss: 0.5480 - accuracy: 0.7083 - precision: 0.6935 - recall: 0.7341 - auc: 0.7974 - f1_score: 0.6614 - val_loss: 0.5659 - val_accuracy: 0.6984 - val_precision: 0.6625 - val_recall: 0.7353 - val_auc: 0.7866 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 91s 1s/step - loss: 0.4906 - accuracy: 0.7619 - precision: 0.7510 - recall: 0.7751 - auc: 0.8452 - f1_score: 0.6614 - val_loss: 0.5648 - val_accuracy: 0.7123 - val_precision: 0.6963 - val_recall: 0.6922 - val_auc: 0.7809 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 92s 1s/step - loss: 0.4269 - accuracy: 0.8063 - precision: 0.8021 - recall: 0.8072 - auc: 0.8866 - f1_score: 0.6614 - val_loss: 0.5475 - val_accuracy: 0.7188 - val_precision: 0.7146 - val_recall: 0.6725 - val_auc: 0.8060 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 91s 1s/step - loss: 0.3849 - accuracy: 0.8270 - precision: 0.8203 - recall: 0.8321 - auc: 0.9090 - f1_score: 0.6614 - val_loss: 0.5563 - val_accuracy: 0.7225 - val_precision: 0.6923 - val_recall: 0.7412 - val_auc: 0.8081 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 91s 1s/step - loss: 0.3194 - accuracy: 0.8651 - precision: 0.8635 - recall: 0.8635 - auc: 0.9385 - f1_score: 0.6614 - val_loss: 0.5849 - val_accuracy: 0.7336 - val_precision: 0.7284 - val_recall: 0.6941 - val_auc: 0.8140 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 87s 1s/step - loss: 0.2417 - accuracy: 0.9044 - precision: 0.9016 - recall: 0.9052 - auc: 0.9654 - f1_score: 0.6614 - val_loss: 0.6169 - val_accuracy: 0.7465 - val_precision: 0.7469 - val_recall: 0.7000 - val_auc: 0.8215 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.3, 'recurrent_dropout': 0.7}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 87s 1s/step - loss: 0.6556 - accuracy: 0.6670 - precision: 0.6533 - recall: 0.6752 - auc: 0.7285 - f1_score: 0.6553 - val_loss: 0.5780 - val_accuracy: 0.6716 - val_precision: 0.6460 - val_recall: 0.6725 - val_auc: 0.7554 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 86s 1s/step - loss: 0.5506 - accuracy: 0.7127 - precision: 0.7056 - recall: 0.7181 - auc: 0.7930 - f1_score: 0.6614 - val_loss: 0.5878 - val_accuracy: 0.6846 - val_precision: 0.6420 - val_recall: 0.7490 - val_auc: 0.7634 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 87s 1s/step - loss: 0.5118 - accuracy: 0.7567 - precision: 0.7488 - recall: 0.7639 - auc: 0.8299 - f1_score: 0.6614 - val_loss: 0.5964 - val_accuracy: 0.7012 - val_precision: 0.6515 - val_recall: 0.7882 - val_auc: 0.7894 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.4421 - accuracy: 0.7952 - precision: 0.7886 - recall: 0.8000 - auc: 0.8768 - f1_score: 0.6614 - val_loss: 0.6014 - val_accuracy: 0.7077 - val_precision: 0.6601 - val_recall: 0.7843 - val_auc: 0.7890 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.3992 - accuracy: 0.8313 - precision: 0.8249 - recall: 0.8361 - auc: 0.9016 - f1_score: 0.6614 - val_loss: 0.5752 - val_accuracy: 0.7253 - val_precision: 0.6865 - val_recall: 0.7686 - val_auc: 0.8034 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.3470 - accuracy: 0.8433 - precision: 0.8395 - recall: 0.8442 - auc: 0.9259 - f1_score: 0.6614 - val_loss: 0.5623 - val_accuracy: 0.7336 - val_precision: 0.6838 - val_recall: 0.8098 - val_auc: 0.8149 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.2929 - accuracy: 0.8841 - precision: 0.8767 - recall: 0.8908 - auc: 0.9491 - f1_score: 0.6614 - val_loss: 0.5973 - val_accuracy: 0.7391 - val_precision: 0.7395 - val_recall: 0.6902 - val_auc: 0.8202 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.2540 - accuracy: 0.8972 - precision: 0.8963 - recall: 0.8956 - auc: 0.9607 - f1_score: 0.6614 - val_loss: 0.5632 - val_accuracy: 0.7623 - val_precision: 0.7364 - val_recall: 0.7725 - val_auc: 0.8429 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.5, 'recurrent_dropout': 0.2}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 91s 1s/step - loss: 0.6905 - accuracy: 0.6290 - precision: 0.6297 - recall: 0.5795 - auc: 0.6947 - f1_score: 0.6553 - val_loss: 0.5994 - val_accuracy: 0.6475 - val_precision: 0.6000 - val_recall: 0.7588 - val_auc: 0.7454 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 91s 1s/step - loss: 0.5838 - accuracy: 0.6813 - precision: 0.6657 - recall: 0.7133 - auc: 0.7596 - f1_score: 0.6614 - val_loss: 0.5915 - val_accuracy: 0.6892 - val_precision: 0.6900 - val_recall: 0.6196 - val_auc: 0.7533 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 93s 1s/step - loss: 0.5510 - accuracy: 0.7214 - precision: 0.7116 - recall: 0.7333 - auc: 0.7937 - f1_score: 0.6614 - val_loss: 0.5711 - val_accuracy: 0.6966 - val_precision: 0.6602 - val_recall: 0.7353 - val_auc: 0.7744 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 91s 1s/step - loss: 0.5073 - accuracy: 0.7560 - precision: 0.7453 - recall: 0.7687 - auc: 0.8324 - f1_score: 0.6614 - val_loss: 0.5982 - val_accuracy: 0.6920 - val_precision: 0.6364 - val_recall: 0.8098 - val_auc: 0.7894 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 92s 1s/step - loss: 0.4727 - accuracy: 0.7917 - precision: 0.7844 - recall: 0.7976 - auc: 0.8598 - f1_score: 0.6614 - val_loss: 0.5518 - val_accuracy: 0.7354 - val_precision: 0.7414 - val_recall: 0.6745 - val_auc: 0.8082 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.4167 - accuracy: 0.8210 - precision: 0.8161 - recall: 0.8233 - auc: 0.8934 - f1_score: 0.6614 - val_loss: 0.5182 - val_accuracy: 0.7465 - val_precision: 0.7235 - val_recall: 0.7490 - val_auc: 0.8239 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.3768 - accuracy: 0.8409 - precision: 0.8355 - recall: 0.8442 - auc: 0.9128 - f1_score: 0.6614 - val_loss: 0.5952 - val_accuracy: 0.7364 - val_precision: 0.6878 - val_recall: 0.8078 - val_auc: 0.8246 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.3175 - accuracy: 0.8710 - precision: 0.8633 - recall: 0.8779 - auc: 0.9388 - f1_score: 0.6614 - val_loss: 0.6118 - val_accuracy: 0.7382 - val_precision: 0.6858 - val_recall: 0.8216 - val_auc: 0.8378 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.5, 'recurrent_dropout': 0.3}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 92s 1s/step - loss: 0.6876 - accuracy: 0.6329 - precision: 0.6293 - recall: 0.6006 - auc: 0.6944 - f1_score: 0.6553 - val_loss: 0.5918 - val_accuracy: 0.6790 - val_precision: 0.6660 - val_recall: 0.6412 - val_auc: 0.7429 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.5882 - accuracy: 0.6885 - precision: 0.6808 - recall: 0.6956 - auc: 0.7532 - f1_score: 0.6614 - val_loss: 0.5757 - val_accuracy: 0.6957 - val_precision: 0.6750 - val_recall: 0.6843 - val_auc: 0.7680 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.5434 - accuracy: 0.7274 - precision: 0.7173 - recall: 0.7398 - auc: 0.7986 - f1_score: 0.6614 - val_loss: 0.5835 - val_accuracy: 0.6929 - val_precision: 0.6712 - val_recall: 0.6843 - val_auc: 0.7724 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.4960 - accuracy: 0.7607 - precision: 0.7597 - recall: 0.7542 - auc: 0.8404 - f1_score: 0.6614 - val_loss: 0.5592 - val_accuracy: 0.7086 - val_precision: 0.6916 - val_recall: 0.6902 - val_auc: 0.7842 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 92s 1s/step - loss: 0.4577 - accuracy: 0.7925 - precision: 0.7964 - recall: 0.7791 - auc: 0.8659 - f1_score: 0.6614 - val_loss: 0.5758 - val_accuracy: 0.7225 - val_precision: 0.6810 - val_recall: 0.7745 - val_auc: 0.8051 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 91s 1s/step - loss: 0.4177 - accuracy: 0.8202 - precision: 0.8128 - recall: 0.8265 - auc: 0.8934 - f1_score: 0.6614 - val_loss: 0.5485 - val_accuracy: 0.7151 - val_precision: 0.6996 - val_recall: 0.6941 - val_auc: 0.8140 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.3687 - accuracy: 0.8504 - precision: 0.8517 - recall: 0.8442 - auc: 0.9175 - f1_score: 0.6614 - val_loss: 0.5628 - val_accuracy: 0.7382 - val_precision: 0.7221 - val_recall: 0.7235 - val_auc: 0.8241 - val_f1_score: 0.6411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.3060 - accuracy: 0.8702 - precision: 0.8726 - recall: 0.8635 - auc: 0.9428 - f1_score: 0.6614 - val_loss: 0.5918 - val_accuracy: 0.7364 - val_precision: 0.7273 - val_recall: 0.7059 - val_auc: 0.8154 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.5, 'recurrent_dropout': 0.5}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 86s 1s/step - loss: 0.6752 - accuracy: 0.6495 - precision: 0.6376 - recall: 0.6507 - auc: 0.7067 - f1_score: 0.6553 - val_loss: 0.5955 - val_accuracy: 0.6605 - val_precision: 0.6558 - val_recall: 0.5902 - val_auc: 0.7405 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 82s 1s/step - loss: 0.5710 - accuracy: 0.6992 - precision: 0.7001 - recall: 0.6843 - auc: 0.7717 - f1_score: 0.6614 - val_loss: 0.5850 - val_accuracy: 0.6781 - val_precision: 0.6378 - val_recall: 0.7353 - val_auc: 0.7635 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.5319 - accuracy: 0.7397 - precision: 0.7400 - recall: 0.7293 - auc: 0.8106 - f1_score: 0.6614 - val_loss: 0.5693 - val_accuracy: 0.7077 - val_precision: 0.6644 - val_recall: 0.7686 - val_auc: 0.7868 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.5046 - accuracy: 0.7575 - precision: 0.7520 - recall: 0.7598 - auc: 0.8356 - f1_score: 0.6614 - val_loss: 0.5492 - val_accuracy: 0.7169 - val_precision: 0.7227 - val_recall: 0.6490 - val_auc: 0.7979 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.4528 - accuracy: 0.7937 - precision: 0.7969 - recall: 0.7815 - auc: 0.8708 - f1_score: 0.6614 - val_loss: 0.5420 - val_accuracy: 0.7502 - val_precision: 0.7098 - val_recall: 0.7961 - val_auc: 0.8186 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.4117 - accuracy: 0.8040 - precision: 0.7973 - recall: 0.8088 - auc: 0.8944 - f1_score: 0.6614 - val_loss: 0.5367 - val_accuracy: 0.7299 - val_precision: 0.7535 - val_recall: 0.6353 - val_auc: 0.8162 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.3717 - accuracy: 0.8333 - precision: 0.8308 - recall: 0.8321 - auc: 0.9147 - f1_score: 0.6614 - val_loss: 0.5928 - val_accuracy: 0.7354 - val_precision: 0.7500 - val_recall: 0.6588 - val_auc: 0.8158 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.3330 - accuracy: 0.8528 - precision: 0.8553 - recall: 0.8450 - auc: 0.9319 - f1_score: 0.6614 - val_loss: 0.6109 - val_accuracy: 0.7465 - val_precision: 0.7027 - val_recall: 0.8020 - val_auc: 0.8242 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.5, 'recurrent_dropout': 0.7}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 93s 1s/step - loss: 0.6686 - accuracy: 0.6529 - precision: 0.6348 - recall: 0.6775 - auc: 0.7168 - f1_score: 0.6553 - val_loss: 0.6132 - val_accuracy: 0.6290 - val_precision: 0.5752 - val_recall: 0.8176 - val_auc: 0.7438 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 92s 1s/step - loss: 0.5697 - accuracy: 0.7028 - precision: 0.6884 - recall: 0.7277 - auc: 0.7739 - f1_score: 0.6614 - val_loss: 0.5765 - val_accuracy: 0.6938 - val_precision: 0.6613 - val_recall: 0.7196 - val_auc: 0.7743 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.5383 - accuracy: 0.7298 - precision: 0.7214 - recall: 0.7382 - auc: 0.8047 - f1_score: 0.6614 - val_loss: 0.5848 - val_accuracy: 0.6846 - val_precision: 0.6302 - val_recall: 0.8020 - val_auc: 0.7761 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.4947 - accuracy: 0.7524 - precision: 0.7478 - recall: 0.7526 - auc: 0.8414 - f1_score: 0.6614 - val_loss: 0.5421 - val_accuracy: 0.7225 - val_precision: 0.7134 - val_recall: 0.6882 - val_auc: 0.8031 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 96s 1s/step - loss: 0.4608 - accuracy: 0.7865 - precision: 0.7867 - recall: 0.7791 - auc: 0.8653 - f1_score: 0.6614 - val_loss: 0.5501 - val_accuracy: 0.7317 - val_precision: 0.7245 - val_recall: 0.6961 - val_auc: 0.8058 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 111s 1s/step - loss: 0.4072 - accuracy: 0.8183 - precision: 0.8166 - recall: 0.8153 - auc: 0.8981 - f1_score: 0.6614 - val_loss: 0.5586 - val_accuracy: 0.7308 - val_precision: 0.7517 - val_recall: 0.6412 - val_auc: 0.8166 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 112s 1s/step - loss: 0.3798 - accuracy: 0.8421 - precision: 0.8407 - recall: 0.8394 - auc: 0.9127 - f1_score: 0.6614 - val_loss: 0.5409 - val_accuracy: 0.7391 - val_precision: 0.7355 - val_recall: 0.6980 - val_auc: 0.8230 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 119s 2s/step - loss: 0.3473 - accuracy: 0.8524 - precision: 0.8529 - recall: 0.8474 - auc: 0.9276 - f1_score: 0.6614 - val_loss: 0.5731 - val_accuracy: 0.7465 - val_precision: 0.7296 - val_recall: 0.7353 - val_auc: 0.8286 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.7, 'recurrent_dropout': 0.2}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 98s 1s/step - loss: 0.7037 - accuracy: 0.6284 - precision: 0.6189 - recall: 0.6182 - auc: 0.6889 - f1_score: 0.6553 - val_loss: 0.6179 - val_accuracy: 0.6642 - val_precision: 0.6806 - val_recall: 0.5431 - val_auc: 0.7212 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 97s 1s/step - loss: 0.6109 - accuracy: 0.6687 - precision: 0.6643 - recall: 0.6659 - auc: 0.7271 - f1_score: 0.6614 - val_loss: 0.5869 - val_accuracy: 0.6651 - val_precision: 0.6076 - val_recall: 0.8196 - val_auc: 0.7706 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 97s 1s/step - loss: 0.5762 - accuracy: 0.6968 - precision: 0.6898 - recall: 0.7020 - auc: 0.7694 - f1_score: 0.6614 - val_loss: 0.5611 - val_accuracy: 0.7114 - val_precision: 0.7181 - val_recall: 0.6392 - val_auc: 0.7802 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 94s 1s/step - loss: 0.5466 - accuracy: 0.7222 - precision: 0.7203 - recall: 0.7157 - auc: 0.7948 - f1_score: 0.6614 - val_loss: 0.5811 - val_accuracy: 0.6883 - val_precision: 0.6367 - val_recall: 0.7902 - val_auc: 0.7812 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 92s 1s/step - loss: 0.5399 - accuracy: 0.7274 - precision: 0.7136 - recall: 0.7486 - auc: 0.8074 - f1_score: 0.6614 - val_loss: 0.5624 - val_accuracy: 0.7012 - val_precision: 0.6587 - val_recall: 0.7608 - val_auc: 0.7925 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 92s 1s/step - loss: 0.5084 - accuracy: 0.7528 - precision: 0.7549 - recall: 0.7398 - auc: 0.8309 - f1_score: 0.6614 - val_loss: 0.5364 - val_accuracy: 0.7169 - val_precision: 0.6984 - val_recall: 0.7039 - val_auc: 0.8042 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 86s 1s/step - loss: 0.4805 - accuracy: 0.7683 - precision: 0.7655 - recall: 0.7655 - auc: 0.8526 - f1_score: 0.6614 - val_loss: 0.5400 - val_accuracy: 0.7086 - val_precision: 0.7070 - val_recall: 0.6529 - val_auc: 0.8052 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 83s 1s/step - loss: 0.4332 - accuracy: 0.7984 - precision: 0.7955 - recall: 0.7968 - auc: 0.8818 - f1_score: 0.6614 - val_loss: 0.5651 - val_accuracy: 0.7317 - val_precision: 0.7052 - val_recall: 0.7412 - val_auc: 0.8131 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.7, 'recurrent_dropout': 0.3}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 94s 1s/step - loss: 0.6832 - accuracy: 0.6468 - precision: 0.6315 - recall: 0.6610 - auc: 0.7036 - f1_score: 0.6553 - val_loss: 0.5917 - val_accuracy: 0.6660 - val_precision: 0.6469 - val_recall: 0.6431 - val_auc: 0.7425 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 93s 1s/step - loss: 0.5989 - accuracy: 0.6698 - precision: 0.6580 - recall: 0.6908 - auc: 0.7391 - f1_score: 0.6614 - val_loss: 0.5755 - val_accuracy: 0.6984 - val_precision: 0.6825 - val_recall: 0.6745 - val_auc: 0.7723 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 94s 1s/step - loss: 0.5727 - accuracy: 0.7079 - precision: 0.6993 - recall: 0.7173 - auc: 0.7743 - f1_score: 0.6614 - val_loss: 0.5661 - val_accuracy: 0.7058 - val_precision: 0.6758 - val_recall: 0.7235 - val_auc: 0.7806 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 95s 1s/step - loss: 0.5403 - accuracy: 0.7333 - precision: 0.7237 - recall: 0.7446 - auc: 0.8044 - f1_score: 0.6614 - val_loss: 0.5615 - val_accuracy: 0.7068 - val_precision: 0.6777 - val_recall: 0.7216 - val_auc: 0.7861 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 94s 1s/step - loss: 0.5205 - accuracy: 0.7345 - precision: 0.7254 - recall: 0.7446 - auc: 0.8173 - f1_score: 0.6614 - val_loss: 0.5566 - val_accuracy: 0.7160 - val_precision: 0.6778 - val_recall: 0.7588 - val_auc: 0.7977 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 93s 1s/step - loss: 0.4839 - accuracy: 0.7651 - precision: 0.7627 - recall: 0.7614 - auc: 0.8467 - f1_score: 0.6614 - val_loss: 0.5912 - val_accuracy: 0.7114 - val_precision: 0.6645 - val_recall: 0.7843 - val_auc: 0.7965 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 94s 1s/step - loss: 0.4715 - accuracy: 0.7778 - precision: 0.7716 - recall: 0.7815 - auc: 0.8569 - f1_score: 0.6614 - val_loss: 0.5446 - val_accuracy: 0.7558 - val_precision: 0.7662 - val_recall: 0.6941 - val_auc: 0.8220 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 93s 1s/step - loss: 0.4462 - accuracy: 0.7940 - precision: 0.7827 - recall: 0.8072 - auc: 0.8724 - f1_score: 0.6614 - val_loss: 0.5375 - val_accuracy: 0.7382 - val_precision: 0.7321 - val_recall: 0.7020 - val_auc: 0.8253 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.7, 'recurrent_dropout': 0.5}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 95s 1s/step - loss: 0.6875 - accuracy: 0.6429 - precision: 0.6296 - recall: 0.6490 - auc: 0.7014 - f1_score: 0.6553 - val_loss: 0.5960 - val_accuracy: 0.6744 - val_precision: 0.6567 - val_recall: 0.6490 - val_auc: 0.7502 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 94s 1s/step - loss: 0.5958 - accuracy: 0.6837 - precision: 0.6812 - recall: 0.6763 - auc: 0.7470 - f1_score: 0.6614 - val_loss: 0.5832 - val_accuracy: 0.6651 - val_precision: 0.6160 - val_recall: 0.7706 - val_auc: 0.7615 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 108s 1s/step - loss: 0.5621 - accuracy: 0.7151 - precision: 0.7051 - recall: 0.7277 - auc: 0.7866 - f1_score: 0.6614 - val_loss: 0.5661 - val_accuracy: 0.6781 - val_precision: 0.6387 - val_recall: 0.7314 - val_auc: 0.7742 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 93s 1s/step - loss: 0.5494 - accuracy: 0.7230 - precision: 0.7128 - recall: 0.7357 - auc: 0.7981 - f1_score: 0.6614 - val_loss: 0.5652 - val_accuracy: 0.6947 - val_precision: 0.6466 - val_recall: 0.7784 - val_auc: 0.7868 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 92s 1s/step - loss: 0.5167 - accuracy: 0.7452 - precision: 0.7335 - recall: 0.7606 - auc: 0.8246 - f1_score: 0.6614 - val_loss: 0.5790 - val_accuracy: 0.7049 - val_precision: 0.6862 - val_recall: 0.6902 - val_auc: 0.7807 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 93s 1s/step - loss: 0.4914 - accuracy: 0.7754 - precision: 0.7714 - recall: 0.7751 - auc: 0.8436 - f1_score: 0.6614 - val_loss: 0.5521 - val_accuracy: 0.7105 - val_precision: 0.6827 - val_recall: 0.7216 - val_auc: 0.8029 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 98s 1s/step - loss: 0.4666 - accuracy: 0.7857 - precision: 0.7760 - recall: 0.7960 - auc: 0.8622 - f1_score: 0.6614 - val_loss: 0.5393 - val_accuracy: 0.7391 - val_precision: 0.7007 - val_recall: 0.7804 - val_auc: 0.8115 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 92s 1s/step - loss: 0.4362 - accuracy: 0.7972 - precision: 0.7863 - recall: 0.8096 - auc: 0.8804 - f1_score: 0.6614 - val_loss: 0.5483 - val_accuracy: 0.7354 - val_precision: 0.7383 - val_recall: 0.6804 - val_auc: 0.8058 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n",
      "- Training with parameters:  {'lstm_activation': 'tanh', 'lstm_dropout': 0.7, 'recurrent_dropout': 0.7}\n",
      "Epoch 1/8\n",
      "79/79 [==============================] - 87s 1s/step - loss: 0.7012 - accuracy: 0.6209 - precision: 0.6152 - recall: 0.5932 - auc: 0.6757 - f1_score: 0.6553 - val_loss: 0.6367 - val_accuracy: 0.6364 - val_precision: 0.6459 - val_recall: 0.5078 - val_auc: 0.6938 - val_f1_score: 0.6411\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 82s 1s/step - loss: 0.6057 - accuracy: 0.6627 - precision: 0.6589 - recall: 0.6578 - auc: 0.7296 - f1_score: 0.6614 - val_loss: 0.5816 - val_accuracy: 0.7003 - val_precision: 0.7163 - val_recall: 0.6039 - val_auc: 0.7611 - val_f1_score: 0.6411\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.5726 - accuracy: 0.7032 - precision: 0.6940 - recall: 0.7141 - auc: 0.7730 - f1_score: 0.6614 - val_loss: 0.5791 - val_accuracy: 0.6836 - val_precision: 0.6615 - val_recall: 0.6745 - val_auc: 0.7668 - val_f1_score: 0.6411\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 91s 1s/step - loss: 0.5273 - accuracy: 0.7393 - precision: 0.7356 - recall: 0.7373 - auc: 0.8147 - f1_score: 0.6614 - val_loss: 0.5698 - val_accuracy: 0.7031 - val_precision: 0.6627 - val_recall: 0.7549 - val_auc: 0.7823 - val_f1_score: 0.6411\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 93s 1s/step - loss: 0.5051 - accuracy: 0.7540 - precision: 0.7451 - recall: 0.7631 - auc: 0.8332 - f1_score: 0.6614 - val_loss: 0.5643 - val_accuracy: 0.7197 - val_precision: 0.7018 - val_recall: 0.7059 - val_auc: 0.7929 - val_f1_score: 0.6411\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.5005 - accuracy: 0.7567 - precision: 0.7492 - recall: 0.7631 - auc: 0.8364 - f1_score: 0.6614 - val_loss: 0.5506 - val_accuracy: 0.7253 - val_precision: 0.7415 - val_recall: 0.6412 - val_auc: 0.8083 - val_f1_score: 0.6411\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 91s 1s/step - loss: 0.4570 - accuracy: 0.7913 - precision: 0.7820 - recall: 0.8008 - auc: 0.8674 - f1_score: 0.6614 - val_loss: 0.5581 - val_accuracy: 0.7262 - val_precision: 0.7421 - val_recall: 0.6431 - val_auc: 0.8131 - val_f1_score: 0.6411\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.4440 - accuracy: 0.7885 - precision: 0.7894 - recall: 0.7799 - auc: 0.8743 - f1_score: 0.6614 - val_loss: 0.5272 - val_accuracy: 0.7438 - val_precision: 0.7161 - val_recall: 0.7569 - val_auc: 0.8189 - val_f1_score: 0.6411\n",
      "  F1-score: 0.64\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tfa.metrics.F1Score(num_classes=1)\n",
    "]\n",
    "\n",
    "# Length of each audio sequence\n",
    "INPUT_LENGTH = 500\n",
    "\n",
    "EPOCHS = 8\n",
    "\n",
    "# Use weights to balance outputs\n",
    "weights = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)\n",
    "weights = dict(enumerate(weights))\n",
    "\n",
    "# Find best parameters during the training\n",
    "optimizer = HyperparameterOptimizer()\n",
    "tunning_params = {\n",
    "    'lstm_activation': ['tanh'],\n",
    "    'lstm_dropout': [0.2, 0.3, 0.5, 0.7],\n",
    "    'recurrent_dropout': [0.2, 0.3, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "best_f1 = -1\n",
    "history = None\n",
    "model = None\n",
    "optimal_params = {}\n",
    "for p in optimizer.tunning_params_combinations(tunning_params):\n",
    "    print('- Training with parameters: ', p)\n",
    "\n",
    "    current_model = create_model(INPUT_LENGTH, METRICS, p)\n",
    "    current_history = current_model.fit(X_train,\n",
    "                                        Y_train,\n",
    "                                        epochs=EPOCHS,\n",
    "                                        validation_data=(X_test, Y_test),\n",
    "                                        verbose=1)\n",
    "\n",
    "    current_f1 = current_history.history['val_f1_score'][-1][0]\n",
    "    print('  F1-score: %.2f' % current_f1)\n",
    "\n",
    "    if best_f1 == -1 or best_f1 < current_f1:\n",
    "        best_f1 = current_f1\n",
    "        optimal_params = p\n",
    "        history = current_history\n",
    "        model = current_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "INFO:tensorflow:Assets written to: /Users/dimasdmm/Documents/Master/Paper_topic/git_project/artifacts/ford-lstm/assets\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'ford-lstm'\n",
    "\n",
    "# Create dir to store the model and store it\n",
    "print('Saving model...')\n",
    "model_loader.create_model_dir(MODEL_NAME)\n",
    "model_loader.save_tf_model(MODEL_NAME, model)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_evaluator = ModelEvaluator()\n",
    "\n",
    "Y_pred = model_evaluator.make_predictions(model, X_test)\n",
    "\n",
    "cm = model_evaluator.compute_confusion_matrix(Y_test, Y_pred)\n",
    "model_scores = {\n",
    "    'accuracy': str(history.history['val_accuracy'][-1]),\n",
    "    'recall': str(history.history['val_recall'][-1]),\n",
    "    'precision': str(history.history['val_precision'][-1]),\n",
    "    'f1': str(history.history['val_f1_score'][-1][0]),\n",
    "    'confusion_matrix': cm.tolist()\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "model_evaluator.subplot_confusion_matrix(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "F1-Score: 0.64\n"
     ]
    }
   ],
   "source": [
    "accuracy = float(model_scores['accuracy'])\n",
    "f1 = float(model_scores['f1'])\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "print('F1-Score: %.2f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving evaluation results...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Saving evaluation results...')\n",
    "model_loader.save_evaluation_results(MODEL_NAME, model_scores)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
